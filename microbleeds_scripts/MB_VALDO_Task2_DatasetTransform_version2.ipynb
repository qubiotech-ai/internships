{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando dataset en: /media/guest/PORT-DISK/Practicas/Microbleeds/nnUNet_raw_data/Dataset888_VALDO_Task2\n",
      "Se encontraron 72 sujetos. Iniciando copia...\n",
      "Procesando sub-327...\n",
      "Copia finalizada.\n",
      "Dataset v2 creado en: /media/guest/PORT-DISK/Practicas/Microbleeds/nnUNet_raw_data/Dataset888_VALDO_Task2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURACIÓN\n",
    "# -----------------------------\n",
    "# Ruta donde están los datos ORIGINALES (raw)\n",
    "ORIGIN_DIR = \"/media/guest/PORT-DISK/Practicas/MicroBleeds/VALDO/Task2\"\n",
    "\n",
    "# Ruta base de nnUNet_raw (donde se creará la nueva carpeta)\n",
    "NNUNET_RAW_BASE = \"/media/guest/PORT-DISK/Practicas/Microbleeds/nnUNet_raw_data\"\n",
    "\n",
    "# ID y Nombre del Dataset (Formato estricto nnUNetv2: DatasetXXX_Nombre)\n",
    "DATASET_ID = 888  # Puedes cambiar este número (ej. 501, 002), pero usa 3 dígitos\n",
    "DATASET_NAME = \"VALDO_Task2\"\n",
    "FOLDER_NAME = f\"Dataset{DATASET_ID}_{DATASET_NAME}\"\n",
    "\n",
    "# Rutas de destino finales\n",
    "TARGET_DIR = os.path.join(NNUNET_RAW_BASE, FOLDER_NAME)\n",
    "IMAGES_TR_DIR = os.path.join(TARGET_DIR, \"imagesTr\")\n",
    "LABELS_TR_DIR = os.path.join(TARGET_DIR, \"labelsTr\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. PREPARACIÓN DE CARPETAS\n",
    "# -----------------------------\n",
    "if os.path.exists(TARGET_DIR):\n",
    "    print(f\"[Aviso] La carpeta destino ya existe: {TARGET_DIR}\")\n",
    "    print(\"Por seguridad, borra la carpeta destino manualmente si quieres regenerarla.\")\n",
    "    # exit() # Descomenta esto si quieres evitar sobrescribir\n",
    "\n",
    "os.makedirs(IMAGES_TR_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_TR_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Generando dataset en: {TARGET_DIR}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. COPIA DE ARCHIVOS\n",
    "# -----------------------------\n",
    "# Buscamos las carpetas de sujetos (sub-XXX)\n",
    "subject_folders = sorted([f for f in os.listdir(ORIGIN_DIR)\n",
    "                          if f.startswith(\"sub\") and os.path.isdir(os.path.join(ORIGIN_DIR, f))])\n",
    "\n",
    "print(f\"Se encontraron {len(subject_folders)} sujetos. Iniciando copia...\")\n",
    "\n",
    "for sub_folder in subject_folders:\n",
    "    src_path = os.path.join(ORIGIN_DIR, sub_folder)\n",
    "    \n",
    "    # Definir rutas origen\n",
    "    # NOTA: Asegúrate de que tus archivos origen coincidan con estos nombres\n",
    "    src_t2s = os.path.join(src_path, f\"{sub_folder}_space-T2S_desc-masked_T2S.nii.gz\")\n",
    "    src_t1  = os.path.join(src_path, f\"{sub_folder}_space-T2S_desc-masked_T1.nii.gz\")\n",
    "    src_t2  = os.path.join(src_path, f\"{sub_folder}_space-T2S_desc-masked_T2.nii.gz\")\n",
    "    src_lbl = os.path.join(src_path, f\"{sub_folder}_space-T2S_CMB.nii.gz\")\n",
    "\n",
    "    # Comprobar que existen antes de copiar\n",
    "    if not all(os.path.exists(p) for p in [src_t2s, src_t1, src_t2, src_lbl]):\n",
    "        print(f\"[ERROR] Faltan archivos en {sub_folder}. Saltando...\")\n",
    "        continue\n",
    "\n",
    "    # Definir rutas destino (Renombrado nnUNetv2)\n",
    "    # T2S -> 0000\n",
    "    # T1  -> 0001\n",
    "    # T2  -> 0002\n",
    "    dst_t2s = os.path.join(IMAGES_TR_DIR, f\"{sub_folder}_0000.nii.gz\")\n",
    "    dst_t1  = os.path.join(IMAGES_TR_DIR, f\"{sub_folder}_0001.nii.gz\")\n",
    "    dst_t2  = os.path.join(IMAGES_TR_DIR, f\"{sub_folder}_0002.nii.gz\")\n",
    "    dst_lbl = os.path.join(LABELS_TR_DIR, f\"{sub_folder}.nii.gz\")\n",
    "\n",
    "    # Copiar (shutil.copy2 preserva metadatos)\n",
    "    print(f\"Procesando {sub_folder}...\", end=\"\\r\")\n",
    "    shutil.copy2(src_t2s, dst_t2s)\n",
    "    shutil.copy2(src_t1, dst_t1)\n",
    "    shutil.copy2(src_t2, dst_t2)\n",
    "    shutil.copy2(src_lbl, dst_lbl)\n",
    "\n",
    "print(f\"\\nCopia finalizada.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. GENERAR DATASET.JSON (Formato v2)\n",
    "# -----------------------------\n",
    "# CAMBIOS CLAVE v2:\n",
    "# - \"modality\" -> \"channel_names\"\n",
    "# - Las claves de channel_names deben ser strings (\"0\", \"1\")\n",
    "# - \"labels\" debe ser mapa Nombre -> Int\n",
    "# - Añadir \"file_ending\"\n",
    "\n",
    "json_dict = {\n",
    "    \"name\": DATASET_NAME,\n",
    "    \"description\": \"Microbleeds detection VALDO Task2 Multi-modal\",\n",
    "    \"tensorImageSize\": \"3D\",\n",
    "    \"reference\": \"VALDO Challenge\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"1.0\",\n",
    "    \n",
    "    # AQUÍ ESTÁ EL CAMBIO CLAVE PARA v2:\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"T2S\",\n",
    "        \"1\": \"T1\",\n",
    "        \"2\": \"T2\"\n",
    "    },\n",
    "    \n",
    "    # Mapeo de etiquetas (Nombre -> Valor píxel)\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"CMB\": 1\n",
    "    },\n",
    "    \n",
    "    \"numTraining\": len(subject_folders),\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "    \n",
    "    # En v2, 'training' es opcional si la carpeta imagesTr está bien,\n",
    "    # pero ponerlo ayuda a depurar.\n",
    "    \"training\": [\n",
    "        {\n",
    "            \"image\": f\"./imagesTr/{sub}.nii.gz\",\n",
    "            \"label\": f\"./labelsTr/{sub}.nii.gz\"\n",
    "        }\n",
    "        for sub in subject_folders\n",
    "    ]\n",
    "    # NOTA: En la sección 'training', NO se pone _0000 en el nombre del archivo.\n",
    "    # nnUNet asume los sufijos de canal automáticamente.\n",
    "}\n",
    "\n",
    "json_path = os.path.join(TARGET_DIR, \"dataset.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(json_dict, f, indent=4)\n",
    "\n",
    "print(f\"Dataset v2 creado en: {TARGET_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
