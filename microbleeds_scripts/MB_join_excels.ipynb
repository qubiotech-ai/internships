{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos cargados. Columnas en B detectadas: ['Subject ID', 'Phase', 'Sex', 'Weight', 'Research Group', 'Visit', 'Archive Date', 'Study Date', 'Age', 'Modality', 'Description', 'Imaging Protocol', 'Image ID']\n",
      "--- RESULTADOS DEL FILTRADO ---\n",
      "IDs con MCH 'Definite' (pacientes con hallazgos): 1812\n",
      "IDs con TYPE en blanco (presuntos sanos): 3868\n",
      "Total de filas tras la limpieza: 15242\n",
      "\n",
      "--- DISTRIBUCIÓN DE MCH POR ID\n",
      "LONI_IMG_ID\n",
      "460695     539\n",
      "399542     525\n",
      "378882     483\n",
      "358741     461\n",
      "342864     458\n",
      "          ... \n",
      "982445       1\n",
      "982371       1\n",
      "981037       1\n",
      "1017752      1\n",
      "1017739      1\n",
      "Length: 1812, dtype: int64\n",
      "\n",
      "Total de filas de MCH (incluyendo repeticiones): 11374\n",
      "\n",
      "--- SLICE THICKNESS EN DATASET LIMPIO (Valores más comunes) ---\n",
      "Slice_Value\n",
      "4.0    15076\n",
      "5.0      164\n",
      "4.5        2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153267/1665609147.py:48: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ids_mch_unicos = df_filtrado[condicion_mch][columna_id_a].nunique()\n",
      "/tmp/ipykernel_153267/1665609147.py:49: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ids_sanos_unicos = df_filtrado[condicion_sanos][columna_id_a].nunique()\n",
      "/tmp/ipykernel_153267/1665609147.py:53: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  conteo_repeticiones = df_filtrado[condicion_mch].groupby(columna_id_a).size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado con éxito en: /media/PORT-DISK/Practicas/MicroBleeds_Generation/ADNI_MCH_Clean_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Configuración de nombres de archivo y columnas\n",
    "archivo_a = '/media/PORT-DISK/Practicas/MicroBleeds_Generation/ADNI_original_dataset_downloaded/MAYOADIRL_MRI_MCH_12Feb2026.csv'\n",
    "archivo_b = '/media/PORT-DISK/Practicas/MicroBleeds_Generation/ADNI_original_dataset_downloaded/idaSearch_2_19_2026.csv'\n",
    "\n",
    "columna_id_a = 'LONI_IMG_ID' \n",
    "columna_id_b = 'Image ID'\n",
    "\n",
    "# 2. Carga de datos con detección de separador\n",
    "try:\n",
    "    df1 = pd.read_csv(archivo_a, sep=None, engine='python')\n",
    "    df2 = pd.read_csv(archivo_b, sep=None, engine='python')\n",
    "    \n",
    "    # Limpiamos posibles espacios en los nombres de las columnas (para evitar el KeyError)\n",
    "    df1.columns = df1.columns.str.strip()\n",
    "    df2.columns = df2.columns.str.strip()\n",
    "    \n",
    "    print(\"Archivos cargados. Columnas en B detectadas:\", df2.columns.tolist())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar archivos: {e}\")\n",
    "    raise\n",
    "\n",
    "# 3. NORMALIZACIÓN DE IDs (Agregado por mí)\n",
    "# En el archivo A: Convertimos a string, quitamos la 'I' del principio y limpiamos espacios\n",
    "df1[columna_id_a] = df1[columna_id_a].astype(str).str.replace(r'^I', '', regex=True).str.strip()\n",
    "\n",
    "# En el archivo B: Aseguramos que sea string y limpiamos espacios\n",
    "df2[columna_id_b] = df2[columna_id_b].astype(str).str.strip()\n",
    "\n",
    "# 4. Realizar el Join (Cruce)\n",
    "df_inner = pd.merge(df1, df2, left_on=columna_id_a, right_on=columna_id_b, how='inner')\n",
    "\n",
    "# 5. Definir filtros de limpieza\n",
    "# Filtro A: TYPE MCH y STATUS Definite\n",
    "condicion_mch = (df_inner['TYPE'] == 'MCH') & (df_inner['STATUS'] == 'Definite')\n",
    "\n",
    "# Filtro B: TYPE en blanco (nulo o vacío)\n",
    "# .isna() detecta NaNs, y el chequeo de string vacío detecta celdas sin texto\n",
    "condicion_sanos = (df_inner['TYPE'].isna()) | (df_inner['TYPE'].astype(str).str.strip() == '') | (df_inner['TYPE'].astype(str) == 'nan')\n",
    "\n",
    "# Aplicar el filtrado final: Solo nos quedamos con una de estas dos opciones\n",
    "df_filtrado = df_inner[condicion_mch | condicion_sanos].copy()\n",
    "\n",
    "# 6. Conteos de IDs ÚNICOS (Individuos/Sesiones)\n",
    "ids_mch_unicos = df_filtrado[condicion_mch][columna_id_a].nunique()\n",
    "ids_sanos_unicos = df_filtrado[condicion_sanos][columna_id_a].nunique()\n",
    "\n",
    "# 7. Conteo de repeticiones (Número de MCH por cada ID)\n",
    "# Esto nos dice cuántos MCH tiene cada ID de los que son 'Definite'\n",
    "conteo_repeticiones = df_filtrado[condicion_mch].groupby(columna_id_a).size()\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "print(f\"--- RESULTADOS DEL FILTRADO ---\")\n",
    "print(f\"IDs con MCH 'Definite' (pacientes con hallazgos): {ids_mch_unicos}\")\n",
    "print(f\"IDs con TYPE en blanco (presuntos sanos): {ids_sanos_unicos}\")\n",
    "print(f\"Total de filas tras la limpieza: {len(df_filtrado)}\")\n",
    "\n",
    "print(f\"\\n--- DISTRIBUCIÓN DE MCH POR ID\")\n",
    "if not conteo_repeticiones.empty:\n",
    "    print(conteo_repeticiones.sort_values(ascending=False))\n",
    "    print(f\"\\nTotal de filas de MCH (incluyendo repeticiones): {conteo_repeticiones.sum()}\")\n",
    "else:\n",
    "    print(\"No se encontraron registros que cumplan la condición de MCH Definite.\")\n",
    "\n",
    "# 8. Análisis de Slice Thickness sobre los filtrados (agregado por mí)\n",
    "if 'Imaging Protocol' in df_filtrado.columns:\n",
    "    df_filtrado['Slice_Value'] = df_filtrado['Imaging Protocol'].str.extract(r'Slice Thickness=([0-9.]+)')\n",
    "    print(\"\\n--- SLICE THICKNESS EN DATASET LIMPIO (Valores más comunes) ---\")\n",
    "    print(df_filtrado['Slice_Value'].value_counts().head(5))\n",
    "\n",
    "\n",
    "# 9. Guardar resultados\n",
    "ruta_base = \"/media/PORT-DISK/Practicas/MicroBleeds_Generation/\"\n",
    "nombre_archivo = \"ADNI_MCH_Clean_Dataset.csv\"\n",
    "ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "\n",
    "# 2. Guardar el DataFrame filtrado\n",
    "# Usamos index=False para no añadir una columna de números extra\n",
    "df_filtrado.to_csv(ruta_completa, index=False)\n",
    "\n",
    "print(f\"Dataset guardado con éxito en: {ruta_completa}\")\n",
    "\n",
    "# En lugar de df_filtrado[condicion_mch], lo correcto para evitar el warning es:\n",
    "# ids_mch_unicos = df_filtrado.loc[df_filtrado['TYPE'] == 'MCH', columna_id_a].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
